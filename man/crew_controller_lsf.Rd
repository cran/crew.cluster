% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/crew_controller_lsf.R
\name{crew_controller_lsf}
\alias{crew_controller_lsf}
\title{\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}} Create a controller with a
LSF launcher.}
\usage{
crew_controller_lsf(
  name = NULL,
  workers = 1L,
  host = NULL,
  port = NULL,
  seconds_interval = 0.25,
  seconds_timeout = 10,
  seconds_launch = 86400,
  seconds_idle = Inf,
  seconds_wall = Inf,
  seconds_exit = 1,
  tasks_max = Inf,
  tasks_timers = 0L,
  reset_globals = TRUE,
  reset_packages = FALSE,
  reset_options = FALSE,
  garbage_collection = FALSE,
  verbose = FALSE,
  command_submit = as.character(Sys.which("bsub")),
  command_delete = as.character(Sys.which("bkill")),
  script_directory = tempdir(),
  script_lines = character(0L),
  lsf_cwd = getwd(),
  lsf_log_output = "/dev/null",
  lsf_log_error = "/dev/null",
  lsf_memory_gigabytes_limit = NULL,
  lsf_memory_gigabytes_required = NULL,
  lsf_cores = NULL
)
}
\arguments{
\item{name}{Name of the client object. If \code{NULL}, a name is automatically
generated.}

\item{workers}{Integer, maximum number of parallel workers to run.}

\item{host}{IP address of the \code{mirai} client to send and receive tasks.
If \code{NULL}, the host defaults to the local IP address.}

\item{port}{TCP port to listen for the workers. If \code{NULL},
then an available ephemeral port is automatically chosen.}

\item{seconds_interval}{Number of seconds between
polling intervals waiting for certain internal
synchronous operations to complete. If \code{space_poll} is \code{TRUE}, then
this is also the minimum number of seconds between calls to
\code{mirai::daemons()} for the purposes of checking worker status.}

\item{seconds_timeout}{Number of seconds until timing
out while waiting for certain synchronous operations to complete.}

\item{seconds_launch}{Seconds of startup time to allow.
A worker is unconditionally assumed to be alive
from the moment of its launch until \code{seconds_launch} seconds later.
After \code{seconds_launch} seconds, the worker is only
considered alive if it is actively connected to its assign websocket.}

\item{seconds_idle}{Maximum number of seconds that a worker can idle
since the completion of the last task. If exceeded, the worker exits.
But the timer does not launch until \code{tasks_timers} tasks
have completed.
See the \code{idletime} argument of \code{mirai::server()}. \code{crew} does not
excel with perfectly transient workers because it does not micromanage
the assignment of tasks to workers, so please allow enough idle
time for a new worker to be delegated a new task.}

\item{seconds_wall}{Soft wall time in seconds.
The timer does not launch until \code{tasks_timers} tasks
have completed.
See the \code{walltime} argument of \code{mirai::server()}.}

\item{seconds_exit}{Number of seconds to wait for NNG websockets
to finish sending large data (when a worker exits after reaching a
timeout or having completed a certain number of tasks).
See the \code{exitlinger} argument of \code{mirai::server()}.}

\item{tasks_max}{Maximum number of tasks that a worker will do before
exiting. See the \code{maxtasks} argument of \code{mirai::server()}.
\code{crew} does not
excel with perfectly transient workers because it does not micromanage
the assignment of tasks to workers, it is recommended to set
\code{tasks_max} to a value greater than 1.}

\item{tasks_timers}{Number of tasks to do before activating
the timers for \code{seconds_idle} and \code{seconds_wall}.
See the \code{timerstart} argument of \code{mirai::server()}.}

\item{reset_globals}{\code{TRUE} to reset global environment
variables between tasks, \code{FALSE} to leave them alone.}

\item{reset_packages}{\code{TRUE} to unload any packages loaded during
a task (runs between each task), \code{FALSE} to leave packages alone.}

\item{reset_options}{\code{TRUE} to reset global options to their original
state between each task, \code{FALSE} otherwise. It is recommended to
only set \code{reset_options = TRUE} if \code{reset_packages} is also \code{TRUE}
because packages sometimes rely on options they set at loading time.}

\item{garbage_collection}{\code{TRUE} to run garbage collection between
tasks, \code{FALSE} to skip.}

\item{verbose}{Logical, whether to see console output and error messages
when submitting worker.}

\item{command_submit}{Character of length 1,
file path to the executable to submit a worker job.}

\item{command_delete}{Character of length 1,
file path to the executable to delete a worker job.
Set to \code{""} to skip manually terminating the worker.
Unless there is an issue with the platform,
the job should still exit thanks to the NNG-powered network programming
capabilities of \code{mirai}. Still, if you set \code{command_delete = ""},
you are assuming extra responsibility for manually monitoring
your jobs on the cluster and manually terminating jobs as appropriate.}

\item{script_directory}{Character of length 1, directory path to the
job scripts. Just before each job submission, a job script
is created in this folder. Script base names are unique to each
launcher and worker, and the launcher deletes the script when the
worker is manually terminated. \code{tempdir()} is the default, but it
might not work for some systems.
\code{tools::R_user_dir("crew.cluster", which = "cache")}
is another reasonable choice.}

\item{script_lines}{Optional character vector of additional lines to be
added to the job script just after the more common flags.
An example would be \code{script_lines = "module load R"} if your cluster
supports R through an environment module.}

\item{lsf_cwd}{Character of length 1, directory to
launch the worker from (as opposed to
the system default). \code{lsf_cwd = "/home"} translates to a line of
\verb{#BSUB -cwd /home} in the LSF job script. \code{lsf_cwd = getwd()} is the
default, which launches workers from the current working directory.
Set \code{lsf_cwd = NULL} to omit this line from the job script.}

\item{lsf_log_output}{Character of length 1, file pattern to control
the locations of the LSF worker log files. By default, both standard
output and standard error go to the same file.
\code{lsf_log_output = "crew_log_\%J.log"} translates to a line of
\verb{#BSUB -o crew_log_\%J.log} in the LSF job script,
where \verb{\%J} is replaced by the job ID of the worker.
The default is \verb{/dev/null} to omit these logs.
Set \code{lsf_log_output = NULL} to omit this line from the job script.}

\item{lsf_log_error}{Character of length 1, file pattern for standard
error. \code{lsf_log_error = "crew_error_\%J.err"} translates to a line of
\verb{#BSUB -e crew_error_\%J.err} in the LSF job script,
where \verb{\%J} is replaced by the job ID of the worker.
The default is \verb{/dev/null} to omit these logs.
Set \code{lsf_log_error = NULL} to omit this line from the job script.}

\item{lsf_memory_gigabytes_limit}{Positive numeric of length 1
with the limit in gigabytes
\code{lsf_memory_gigabytes_limit = 4}
translates to a line of \verb{#BSUB -M 4G}
in the LSF job script.
\code{lsf_memory_gigabytes_limit = NULL} omits this line.}

\item{lsf_memory_gigabytes_required}{Positive numeric of length 1
with the memory requirement in gigabytes
\code{lsf_memory_gigabytes_required = 4}
translates to a line of \verb{#BSUB -R 'rusage[mem=4G]'}
in the LSF job script.
\code{lsf_memory_gigabytes_required = NULL} omits this line.}

\item{lsf_cores}{Optional positive integer of length 1,
number of CPU cores for the worker.
\code{lsf_cores = 4} translates
to a line of \verb{#BSUB -n 4} in the LSF job script.
\code{lsf_cores = NULL} omits this line.}
}
\description{
Create an \code{R6} object to submit tasks and
launch workers on LSF workers.
}
\details{
WARNING: the \code{crew.cluster} LSF plugin is experimental
and has not actually been tested on a LSF cluster. Please proceed
with caution and report bugs to
\url{https://github.com/wlandau/crew.cluster}.
}
\section{Attribution}{

The template files at
\url{https://github.com/mschubert/clustermq/tree/master/inst}
informed the development of the \code{crew} launcher plugins in
\code{crew.cluster}, and we would like to thank
Michael Schubert for developing \code{clustermq} and releasing it under
the permissive Apache License 2.0.
See the \code{NOTICE} and \code{README.md} files in the \code{crew.cluster}
source code for additional attribution.
}

\examples{
if (identical(Sys.getenv("CREW_EXAMPLES"), "true")) {
controller <- crew_controller_lsf()
controller$start()
controller$push(name = "task", command = sqrt(4))
controller$wait()
controller$pop()$result
controller$terminate()
}
}
\seealso{
Other controllers: 
\code{\link{crew_controller_pbs}()},
\code{\link{crew_controller_sge}()},
\code{\link{crew_controller_slurm}()}
}
\concept{controllers}
